\section{Related Work}
\label{sec:relatedwork}
% alternatives: What is different approaches/alternative to NIDS has there been before?
%(p1: In the related work, you should maybe start with a paragraph where you introduce anomaly detection, and describe what alternatives there are. As I remember it, there are approaches that do one-class classification (and do not try to group anomalies at all), and cluster based approaches (which is what you do). As it is now, you jump directly in sentence 2 of Related Work into an explanation about different clustering methods.)
For an overview of different anomaly detection methods and applications, mostly semi-supervised or unsupervised approaches have previously been applied to anomaly detection problems including one-class SVM \cite{ester96}, bayesian method \cite{holst12}, graph stream \cite{aggarwal01} and distance-based method \cite{ramaswamy00} because those approaches can handle imbalanced datasets and make use of unlabeled data which is cheaper to obtain than labeled data. 
However, when the intrusions occur collectively among a background of normal data, those approaches are not effective since they are limited to finding point anomalies as known as outliers. 
So clustering analysis \cite{breuning00} \cite{knorr00} are preferred in the context of collective anomaly detection. 

%Semi-supervised or unsupervised approaches are preferred in intrusion detection \cite{chandola09} because it can handle imbalanced datasets and make use of unlabeled data which is cheaper to obtain than labeled data.
%Clustering analysis is an important tool for those approaches so also studied in the context of network anomaly detection \cite{chandola09}. 
%Clustering approaches to network intrusion detection systems can be divided into two methods 
%- distance-based \cite{ramaswamy00}\cite{knorr00} and density-based methods \cite{aggarwal01}\cite{breuning00}\cite{ester96}. 
%In the context of intrusion detection, clustering analysis is \cite{ramaswamy00} \cite{knorr00} is an effective tool so the method presented here is also based on clustering algorithm.  
%The method presented here is based on clustering analysis since it is an important tool for semi-those approaches so also studied in the context of network anomaly detection \cite{chandola09}. 
% problems : In what way they differ from each other
Clustering approaches, however, have several drawbacks. 
Firstly, they are hard to be easily generalized in multi-dimensional data because the neighborhood can be arbitrary. 
Secondly, a major drawback to clustering algorithm is that anomalies which should not belong to any cluster can be assigned to a larger cluster. 
% because clustering algorithm force every instance to be assigned to a cluster. 
Thirdly, it is subjective to choose $k$, the number of clusters, so not applicable to the case of dynamic intrusion detection. 
Especially in the case studied here, where the size of abnormal class is varied, finding $k$ is very important. 

% alternatives
Compared to the those clustering algorithms, spectral clustering has advantages. 
The spectral clustering approach solves the graph cutting problem. 
It often outperforms the other clustering approaches \cite{ulrike07}, and it offers proper way of finding $k$. 
Graph cutting is the intractable optimization problem which is associated with clustering algorithms. 
The naive graph cut algorithm is the NP-hard problem and noise-sensitive. 
To diminish those weaknesses, normalized cut \cite{jianbo00} is proposed which solves the NP-hard problem by approximate solution. 
Spectral clustering according to Jordan and Francis \cite{jordan04} and Ng, Jordan and Weiss \cite{ng01} proposed a new algorithm for spectral clustering with objective function with different normalized terms that minimize the error. 
Dhillon et al. \cite{dhillon04}, and Ding and He \cite{cding04} showed that the objective function is equivalent to weighted kernel k-means algorithm.
However since all of them try to divide data points into only two classes, it is sensitive to noise.
I use Shi's multiclass spectral clustering \cite{jianbo03} to alleviate noise problem because I found recursive bipartite approach is not applicable for real data which has much noise. 

% solutions
In this report, I will design the intrusion detection system using spectral clustering as a promising alternative. 
It uses both distance-based and density-based methods to solve those three problems stated above. 
Firstly, it will utilize the EM approach to automatically learn the similarity score function to reduce dimensions of raw data.
Secondly, it will learn density function for normal connections to find anomalies within a cluster which is classified as normal connections. 
Thirdly, this one uses the top eigenvectors to find best $k$ and finds clusters as an approximative solution to graph cut problem. % which is the intractable optimization problem. %with an eigenvalue decomposition and graph cut algorithm. 

% Remainder
The remainder of this report is structured as follows. 
Section~\ref{sec:potentialanomalies} describes potential anomalies in the data set. 
Section~\ref{sec:spectralclustering} describes the detail of the spectral clustering algorithm. 
More details can be found in \cite{ulrike07}. 
Section~\ref{sec:connectionsimilarity} describes how to train a similarity score function and a density function. 
Section~\ref{sec:experiments} illustrates how the method works on the NSL-KDD data. 
Section~\ref{sec:conclusion} offers concluding remarks. 
%It is called a spectral clustering as well. 
%Mostly spectral clustering is used in the spatial analysis such as image segmentation and their performances are generally good especially for non-convex clustering problem. 
%I will utilize the EM approach to automatically learn the similarity score functions and density function for normal network connections. %before the clustering. 
%This semi-supervised learning ensures that it is useful for the case of normal behaviours, and easy to bring prior knowledge. 
%that multi-lcass spectral clustering with EM algorithm and density estimation. 
%Although spectral clustering only requires pairwise similarity of data points, I use semi-supervised way of learning. 
%it does not consider density which is. 
%I uses histogram and mixture models to measure its similarity.
