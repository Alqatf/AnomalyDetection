\section{Related Work}
\label{sec:relatedwork}
% alternatives: What is different approaches/alternative to NIDS has there been before?
Semi-supervised or unsupervised approaches are preferred in intrusion detection \cite{chandola09} because it can handle imbalanced datasets and make use of unlabeled data which is cheaper to obtain than labeled data.
Clustering analysis is an important tool for those approaches so also studied in the context of network anomaly detection \cite{chandola09}. 
Clustering approaches to network intrusion detection systems can be divided into two methods 
- distance-based \cite{ramaswamy00}\cite{knorr00} and density-based methods \cite{aggarwal01}\cite{breuning00}\cite{ester96}. 

% problems : In what way they differ from each other
Clustering approaches, however, have several drawbacks. 
Firstly, they are hard to be easily generalized in multi-dimensional data because the neighborhood can be arbitrary. 
Secondly, a major drawback to clustering algorithm is that anomalies which should not belong to any cluster can be assigned to a larger cluster. 
% because clustering algorithm force every instance to be assigned to a cluster. 
Thirdly, it is subjective to choose $k$, the number of clusters, so not applicable to the case of dynamic intrusion detection. 
Especially in the case studied here, where the size of abnormal class is varied, finding $k$ is very important. 

% alternatives
Compared to the those clustering algorithms, spectral clustering has advantages. 
The spectral clustering approach solves the graph cutting problem. 
It often outperforms the other clustering approaches \cite{ulrike07}, and it offers proper way of finding $k$. 
Graph cutting is the intractable optimization problem which is associated with clustering algorithms. 
The naive graph cut algorithm is the NP-hard problem and noise-sensitive. 
To diminish those weaknesses, normalized cut \cite{jianbo00} is proposed which solves the NP-hard problem by approximate solution. 
Spectral clustering according to Jordan and Francis \cite{jordan04} and Ng, Jordan and Weiss \cite{ng01} proposed a new algorithm for spectral clustering with objective function with different normalized terms that minimize the error. 
Dhillon et al. \cite{dhillon04}, and Ding and He \cite{cding04} showed that the objective function is equivalent to weighted kernel k-means algorithm.
However since all of them try to divide data points into only two classes, it is sensitive to noise.
I use Shi's multiclass spectral clustering \cite{jianbo03} to alleviate noise problem because I found recursive bipartite approach is not applicable for real data which has much noise. 

% solutions
In this report, I will design the intrusion detection system using spectral clustering as a promising alternative. 
It uses both distance-based and density-based methods to solve those three problems stated above. 
Firstly, it will utilize the EM approach to automatically learn the similarity score function to reduce dimensions of raw data.
Secondly, it will learn density function for normal connections to find anomalies within a cluster which is classified as normal connections. 
Thirdly, this one uses the top eigenvectors to find best $k$ and finds clusters as an approximative solution to graph cut problem. % which is the intractable optimization problem. %with an eigenvalue decomposition and graph cut algorithm. 

% Remainder
The remainder of this report is structured as follows. 
Section~\ref{sec:potentialanomalies} describes potential anomalies in the data set. 
Section~\ref{sec:spectralclustering} describes the detail of the spectral clustering algorithm. 
More details can be found in \cite{ulrike07}. 
Section~\ref{sec:connectionsimilarity} describes how to train a similarity score function and a density function. 
Section~\ref{sec:experiments} illustrates how the method works on the NSL-KDD data. 
Section~\ref{sec:conclusion} offers concluding remarks. 
%It is called a spectral clustering as well. 
%Mostly spectral clustering is used in the spatial analysis such as image segmentation and their performances are generally good especially for non-convex clustering problem. 
%I will utilize the EM approach to automatically learn the similarity score functions and density function for normal network connections. %before the clustering. 
%This semi-supervised learning ensures that it is useful for the case of normal behaviours, and easy to bring prior knowledge. 
%that multi-lcass spectral clustering with EM algorithm and density estimation. 
%Although spectral clustering only requires pairwise similarity of data points, I use semi-supervised way of learning. 
%it does not consider density which is. 
%I uses histogram and mixture models to measure its similarity.
