\section{Experiments}
I performed experiments to evaluate the performances of similarity measures and algorithms in Section~\ref{sec:connectionsimilarity}.
\newline
In Section~\ref{subsec:datasetandsetup}, I describe the dataset that I used for the experiements.\newline
In Section~\ref{subsec:detectinganomalies}, I evaluate how successful the algorithms are in detecting different types of anomalies.

\subsection{Dataset and Setup}
\label{subsec:datasetandsetup}
For experiments, I select the NSL-KDD dataset. 
It is a up-to-date version of KDD dataset which is widely used for network-based intrusion detection. 
Since the NSL-KDD dataset solves issues in the original data set, I use the data set in this report as an effective benchmark. 
% All source code is on the Internet. 

\begin{figure}[htb2]
\begin{center}
%\item Selection of raw data
%\begin{inparaenum}[\itshape a\upshape)]
%\item Data preprocessing
%\item Data transformation
%\item Affinity matrix computation
%\item Clustering
%\item Outlier detection
%\end{inparaenum}
\end{center}
\caption{Overview of Intrusion Detection System}
\label{fig:refSingleRobot1}
\end{figure}

\begin{figure}[htb2]
\begin{center}
\end{center}
\caption{Similarity of normal and abnormal connections in training set} % I may show rest of data in appendix
\label{fig:refSingleRobot1}
\end{figure}

%\subsection{Computing affinity matrix}
%%The processing steps of the approach can be summerized as follows:
%%1) Training mixture model with training set containing records of both normal and anomalous connections.
%%2) The data are divided into different clusters for normal and anomalous connections using Spectral clustering algorithm.
%\subsubsection{Data pre-processing}
%\begin{itemize}
%\item categorical value to integer e.g.) service-type (ftp-data,http,etc).
%\item log of big number e.g.) duration, src-bytes.
%\end{itemize}
%\subsubsection{Affinity matrix computation}
%The data points are associated with each other by pairwise similarity.
%\begin{itemize}
%\item Construct similarity matrix with distance metric.
%\item Construct affinity matrix from similarity matrix with 8-nearest neighbors algorithm.
%\end{itemize}
%\subsection{Clustering}
%%\subsubsection{Number of clusters prediction}
%%Predict number of clusters based on the eigengap.
%%\subsubsection{Spectral clustering algorithm}
%%Normalized cut algorithm. \cite{jianbo00}
%%\subsubsection{Representative of clusters}
%%Clusters are represented by the mean and variance.
%\subsection{Detecting anomaly from clusters}
%%Distance based outlier detection is used.
%%\begin{itemize}
%%\item It do not require any prior knowledge.
%%\item k-nearest neighbor outlier detection algorithm. \cite{knorr00}
%%\end{itemize}

In order for spectral anaysis, we need to make a sparse affinity matrix from training set. 
We can compute a sparse affinity matrix from a pairwise similarity matrix. 
A new approach to construct a pairwise similarity matrix is that compares their probability in pairwise not its attributes directly. 
To calculate the probability for data point, mixure models for each classes and attributes are used. 
The EM approach is guaranteed to converge to a local optimum on given input. 
The experiment suggest that such local optimum can effectively seperate different connections and most of unknown classes. (Figure) 
After we have a pairwise similarity matrix, one way to convert similarity matrix to a sparse affinity matrix is that dealing with the affinities for $k$ nearest neighborhood only, and set all other values for current data point to zero. 
I choose the $k = 8$ because it is common in other practices. 

\subsection{Detecting Anomalies}
\label{subsec:detectinganomalies}
In this section, I describe how the a sparse affinity matrix can be used to detect point and collective anomalies.

\subsubsection{Known Anomalies}
We see that normal and abnormal connections similarity are sensitive to known anomalies. 
% The similarity coputed by mixture models gives similarity scores that are used to find k nearest neighborhood.
\begin{figure}[htb2]
\begin{center}
\end{center}
\caption{Similarity of normal and abnormal connections in training set} % I may show rest of data in appendix
\label{fig:refSingleRobot1}
\end{figure}

\subsubsection{Unknown Anomalies}
We see that normal and abnormal connection similarity are also sensitive to most of unknown anomaly. 
However, we have four classes that is similar to normal connections. 
Connection density similarity measure is sensitive in this type of anomaly if it is above its threshold. 
However this approach does not work if the data points are insufficient to form high density.

\begin{figure}[htb2]
\begin{center}
\end{center}
\caption{Similarity to normal and abnormal connections in test set} % I may show rest of data in appendix
\label{fig:refSingleRobot1}
\end{figure}

For clustering, there is two ways to do it.
First is k-cluster and the other is one by one. I followed both way but one-by-one is sometimes really bad.

Some case eigengap works otherwise it does not work. Therefore I pick some case.
So noise really matters. Especially newly added data can be considered as noise. of course some of them are not.
