\section{Connection Similarity}
\label{sec:connectionsimilarity}
The problem of comparing network connection similarity has been an important problem. %\cite{}
Since there is not only one normal state, I generated mixture models for normal connections for each protocols and attributes.
After reviewing the families of proposed schemes, I indentified similarity and density approaches as the promising for the problem.
\newline
In Section~\ref{subsec:problemformulation}, I describe the problem.\newline
In Section~\ref{subsec:normalabnormalsimilarity}, I propose new approaches to measure similarity.\newline
In Section~\ref{subsec:densitysimilarity}, I describe density similarity measurement which is relied on the way of representatives of the clusters and threshold.\newline
In Section~\ref{subsec:learningsimilarity}, I describe how the algorithm learn mixture models with training set.\newline

\subsection{Problem formulation}
\label{subsec:problemformulation}
Given dataset, we can learn normal/abnormal mixture models, and estimate a density of normal connections from training set.
Anomalies can be detected by cluster algorithm based on affinity matrix which is computed by similarity score, or by comparing density of clusters against threshold.

\subsection{Normal/Abnormal Connection Similarity}
\label{subsec:normalabnormalsimilarity}
Two nodes are similar if their similarity to normal/abnormal mixture models are similar.
Mixture models can be learned by EM algorithm, and compute the similarity score, log probability of each connections, under the model.
The EM approach is guaranteed to converge to a local optimum on a given input.
We define the similarity between two nodes using cosine distance of normal and abnormal similarity scores.

\begin{equation}
    sim(V, V') = \frac{A \cdot B}{|A| |B|}
\end{equation}

\subsection{Connection Density Similarity}
\label{subsec:densitysimilarity}
A cluster is normal if its mean and variance to a mixture model for normal connections is similar. 
We can adjust threshold if false-positive or false-negative is high. 

\subsection{Learning Mixture Models}
\label{subsec:learningsimilarity}
EM algorithms to learn mixture models.
Learned 234(=2 x 3 x 39) Gaussian mixture models in total.
\begin{itemize}
\item 2 : one for normal, one for abnormal.
\item 3 : each per each protocol e.g.) udp, icmp, tcp.
\item 39 : for all attributes.
\end{itemize}

%\subsubsection{Measuring similarity}
%\label{subsec:densitysimilarity}
%Gaussian mixture models from training set helps to measure those two similarity per each connection.
%\begin{itemize}
%\item Similarity to known normal behavior.
%\item Similarity to known abnormal behavior.
%\end{itemize}
